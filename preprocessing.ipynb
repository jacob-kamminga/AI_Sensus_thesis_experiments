{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fd9ddb-38fb-4baa-a984-c899ccbec87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# ------------------------------------------ #\n",
    "#  Pre-Processing Constants:\n",
    "# ------------------------------------------ #\n",
    "\n",
    "# Label encoder used to get a numeric representation of a label\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# The activities\n",
    "LABELS = ['grazing', 'running', 'trotting', 'standing', 'walking-natural', 'walking-rider']\n",
    "\n",
    "# Add columns to drop from dataframe\n",
    "REMOVE_COLUMNS = ['Mx', 'My', 'Mz', 'A3D', 'G3D', 'M3D']\n",
    "\n",
    "# Add subjects you want to include\n",
    "SUBJECTS = ['Galoway', 'Patron', 'Happy', 'Driekus']\n",
    "\n",
    "# Amount of features (xyz acc / xyz gyr)\n",
    "N_FEATURES = 6\n",
    "\n",
    "# Name of the column used as output\n",
    "OUTPUT_LABEL = 'ActivityEncoded'\n",
    "\n",
    "# Sliding windows parameters\n",
    "TIME_PERIODS = 200\n",
    "STEP_DISTANCE = 100\n",
    "\n",
    "# Datasets\n",
    "PATH = '/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/*'\n",
    "FILES = sorted(glob.glob(PATH))\n",
    "\n",
    "\n",
    "# ------------------------------------------ #\n",
    "#  Helper functions:\n",
    "# ------------------------------------------ #\n",
    "\n",
    "def create_dataframe(files):\n",
    "    \"\"\"\n",
    "    Simple function to set up dataframe and initial clean-up of the data\n",
    "    files: path to files\n",
    "    returns: dataframe\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame()\n",
    "    # Pick only the files in SUBJECTS\n",
    "    matching = [f for f in files if any(s in f for s in SUBJECTS)]\n",
    "\n",
    "    for file in matching:\n",
    "        csv = pd.read_csv(file)\n",
    "        csv['filename'] = file\n",
    "        result = result.append(csv)\n",
    "\n",
    "    # remove redundant columns\n",
    "    result.drop(REMOVE_COLUMNS, axis=1, inplace=True)\n",
    "    result = select_activities(result)\n",
    "    # create a new column with a unique integer value for each label\n",
    "    result[OUTPUT_LABEL] = le.fit_transform(result['label'].values.ravel())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def select_activities(df):\n",
    "    df['label'] = df['label'].replace(to_replace=['trotting-natural'], value='trotting')\n",
    "    df['label'] = df['label'].replace(to_replace=['trotting-rider'], value='trotting')\n",
    "    df['label'] = df['label'].replace(to_replace=['running-natural'], value='running')\n",
    "    df['label'] = df['label'].replace(to_replace=['running-rider'], value='running')\n",
    "    result = df[df['label'].isin(LABELS)]\n",
    "    return result\n",
    "\n",
    "\n",
    "def split_by_subject(df, name):\n",
    "    test = df[df['filename'].str.contains(name)]\n",
    "    train = df[~df['filename'].str.contains(name)]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def feature_scaling(df):\n",
    "    train_x_max = df['Ax'].max()\n",
    "    train_y_max = df['Ay'].max()\n",
    "    train_z_max = df['Az'].max()\n",
    "\n",
    "    train_gx_max = df['Gx'].max()\n",
    "    train_gy_max = df['Gy'].max()\n",
    "    train_gz_max = df['Gz'].max()\n",
    "\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    # divide all 3 axis with the max value in the training set\n",
    "    df['Ax'] = df['Ax'] / train_x_max\n",
    "    df['Ay'] = df['Ay'] / train_y_max\n",
    "    df['Az'] = df['Az'] / train_z_max\n",
    "\n",
    "    df['Gx'] = df['Gx'] / train_gx_max\n",
    "    df['Gy'] = df['Gy'] / train_gy_max\n",
    "    df['Gz'] = df['Gz'] / train_gz_max\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_windows(df, time_steps, step, label_name):\n",
    "    windows = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        axs = df['Ax'].values[i: i + time_steps]\n",
    "        ays = df['Ay'].values[i: i + time_steps]\n",
    "        azs = df['Az'].values[i: i + time_steps]\n",
    "\n",
    "        gxs = df['Gx'].values[i: i + time_steps]\n",
    "        gys = df['Gy'].values[i: i + time_steps]\n",
    "        gzs = df['Gz'].values[i: i + time_steps]\n",
    "        # Retrieve the most often used label in this segment\n",
    "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "        windows.append([axs, ays, azs, gxs, gys, gzs])\n",
    "        labels.append(label)\n",
    "    # Bring the segments into a better shape\n",
    "    reshaped_windows = np.asarray(windows, dtype=np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return reshaped_windows, labels\n",
    "\n",
    "\n",
    "# Reshape input into a format compatible with the NN\n",
    "def reshape_input(x, shape):\n",
    "    result = x.reshape(x.shape[0], shape)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Apply one hot coding to output\n",
    "def encode_output(y, classes):\n",
    "    result = np_utils.to_categorical(y, classes)\n",
    "    return result\n",
    "\n",
    "\n",
    "def preprocess_training(df, input_shape, num_classes):\n",
    "    train = feature_scaling(df)\n",
    "    x_train, y_train = create_windows(train, TIME_PERIODS, STEP_DISTANCE, OUTPUT_LABEL)\n",
    "    x_train, y_train = shuffle(np.array(x_train), np.array(y_train))\n",
    "\n",
    "    x_train = reshape_input(x_train, input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    y_train = y_train.astype('float32')\n",
    "    y_train = encode_output(y_train, num_classes)\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "def preprocess_test(df, input_shape, num_classes):\n",
    "    test = feature_scaling(df)\n",
    "    x_test, y_test = create_windows(test, TIME_PERIODS, STEP_DISTANCE, OUTPUT_LABEL)\n",
    "\n",
    "    x_test = reshape_input(x_test, input_shape)\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "    y_test = encode_output(y_test, num_classes)\n",
    "\n",
    "    return x_test, y_test\n",
    "\n",
    "\n",
    "def preprocess(df, test_subject):\n",
    "    input_shape = (TIME_PERIODS * N_FEATURES)\n",
    "    num_classes = len(LABELS)\n",
    "    train, test = split_by_subject(df, test_subject)\n",
    "    x_train, y_train = preprocess_training(train, input_shape, num_classes)\n",
    "    x_test, y_test = preprocess_test(test, input_shape, num_classes)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, input_shape, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48212a2-823f-4b37-b168-157a208acd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
