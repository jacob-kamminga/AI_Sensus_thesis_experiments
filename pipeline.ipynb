{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2560d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting and printing\n",
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#machine learning packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#other packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "#file management\n",
    "import glob\n",
    "import os\n",
    "\n",
    "#database information\n",
    "from datetime import date\n",
    "from peewee import *\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1359392c",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6da770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now, you can log in to Maartje's username. Later, this should be changed to separate users.\\n\",\n",
    "name = 'maartjehuveneers'\n",
    "pw = 'p4RwxJCchw7Ljqhv'\n",
    "\n",
    "#Settings for the experiment\n",
    "#Include the model description here, as this is NOT included in the parameters\n",
    "DESCRIPTION = \"Neural Network with 6 layers (Reshape, Dense x3, Flatten, Dense)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc75f5",
   "metadata": {},
   "source": [
    "# Database setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a82238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting up database\n",
    "db = MySQLDatabase('HorsingAround', user=name, password=pw,\n",
    "                         host='www.jacobkamminga.nl', port=3306)\n",
    "\n",
    "class Experiment(Model):\n",
    "    key = UUIDField()\n",
    "    username = TextField()\n",
    "    test_horse = TextField()\n",
    "    date = DateField()\n",
    "    accuracy_experiment = FloatField()\n",
    "    fscore = FloatField()\n",
    "    mcc = FloatField()\n",
    "    recall = FloatField()\n",
    "    confusion_matrix = BlobField()\n",
    "    parameters = TextField()\n",
    "    description = TextField()\n",
    "    class Meta:\n",
    "        database = db\n",
    "\n",
    "class Activity(Model):\n",
    "    key = UUIDField()\n",
    "    test_horse = TextField()\n",
    "    activity = TextField()\n",
    "    accuracy_activity = FloatField()\n",
    "    recall_activity = FloatField()\n",
    "    specificity = FloatField()\n",
    "    precision = FloatField()\n",
    "    TP = IntegerField()\n",
    "    TN = IntegerField()\n",
    "    FP = IntegerField()\n",
    "    FN = IntegerField()\n",
    "    class Meta:\n",
    "        database = db\n",
    "\n",
    "db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27f9e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next lines are used to create a new table in the database, don't uncomment this unless needed. Otherwise we make a new table every time we run the program\n",
    "\n",
    "db.drop_tables([Experiment, Activity])\n",
    "db.create_tables([Experiment, Activity])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b39810a",
   "metadata": {},
   "source": [
    "# Labels and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ffff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some styling\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "sns.set()\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#Label encoder used to get a numeric representation of a label\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#The activities\n",
    "LABELS = ['standing',\n",
    "          'walking-natural',\n",
    "          'walking-rider',\n",
    "          'trotting-natural',\n",
    "          'trotting-rider',\n",
    "          'running-natural',\n",
    "          'running-rider',\n",
    "          'jumping',\n",
    "          'grazing',\n",
    "          'eating',\n",
    "          'head shake',\n",
    "          'shaking',\n",
    "          'scratch-biting',\n",
    "          'rubbing',\n",
    "          'fighting',\n",
    "          'rolling',\n",
    "          'scared']\n",
    "\n",
    "#Sliding windows\n",
    "TIME_PERIODS = 200\n",
    "STEP_DISTANCE = 100\n",
    "\n",
    "#Datasets\n",
    "FILES = sorted(glob.glob('Data/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea5fe71",
   "metadata": {},
   "source": [
    "# Set up dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f8e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_COLUMNS = ['Mx', 'My', 'Mz','A3D','G3D','M3D'] #Add columns to drop from dataframe\n",
    "\n",
    "def loadDataFrame(files):\n",
    "    \"\"\"\n",
    "    Simple function to set up dataframe and initial clean-up of the data\n",
    "    files: path to files\n",
    "    returns: combined dataframe of all files\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        csv = pd.read_csv(file)\n",
    "        csv['filename']=file\n",
    "        df = df.append(csv)\n",
    "        \n",
    "    df.drop(REMOVE_COLUMNS, axis=1, inplace=True)\n",
    "    df['ActivityEncoded'] = le.fit_transform(df['label'].values.ravel())\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_to_float(x):\n",
    "\n",
    "    try:\n",
    "        return np.float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "df = loadDataFrame(FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e8aa4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot data composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f99741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def show_basic_dataframe_info(dataframe):\n",
    "\n",
    "#     # Shape and how many rows and columns\n",
    "#     print('Number of columns in the dataframe: %i' % (dataframe.shape[1]))\n",
    "#     print('Number of rows in the dataframe: %i\\n' % (dataframe.shape[0]))\n",
    "\n",
    "# show_basic_dataframe_info(df)\n",
    "# df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac3439c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting activity data\n",
    "\n",
    "#Training examples per activity type\n",
    "# SECONDS = 10 #nr of seconds to display accelerometer data\n",
    "# SAMPLING_RATE = 20 #the sampling rate at which data was recorded\n",
    "\n",
    "# def plot_activity(activity, data):\n",
    "#     fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 4))\n",
    "#     l1, = ax[0].plot(data['datetime'], data['Ax'], label=\"X-axis\")\n",
    "#     l2, = ax[0].plot(data['datetime'], data['Ay'], label=\"Y-Axis\")\n",
    "#     l3, = ax[0].plot(data['datetime'], data['Az'], label=\"Z-Axis\")\n",
    "#     ax[0].set_ylabel('Acceleration (m/$s^2$)')\n",
    "#     ax[0].set_xlabel('Time')\n",
    "#     ax[0].legend(handles=[l1,l2,l3], loc='lower right')\n",
    "#     ax[0].xaxis.set_ticks([])\n",
    "#     ax[0].set_title(activity+\" accelerometer data over time\")\n",
    "#     ax[0].grid(False)\n",
    "    \n",
    "#     l1, = ax[1].plot(data['datetime'], data['Gx'], label=\"X-axis\")\n",
    "#     l2, = ax[1].plot(data['datetime'], data['Gy'], label=\"Y-Axis\")\n",
    "#     l3, = ax[1].plot(data['datetime'], data['Gz'], label=\"Z-Axis\")\n",
    "#     ax[1].set_ylabel('Angular velocity ($^\\circ$/s)')\n",
    "#     ax[1].set_xlabel('Time')\n",
    "#     ax[1].legend(handles=[l1,l2,l3], loc='lower right')\n",
    "#     ax[1].xaxis.set_ticks([])\n",
    "#     ax[1].set_title(activity+\" gyroscope data over time\")\n",
    "#     ax[1].grid(False)\n",
    "#     plt.tight_layout()\n",
    "#     if(activity == 'eating' or activity == 'running-natural' or activity == 'shaking'):\n",
    "#         plt.savefig(activity)\n",
    "#     plt.show()\n",
    "\n",
    "# #plot all 3 subplots for each activity\n",
    "# for activity in np.unique(df['label']):\n",
    "#     subset = df[df['label'] == activity][:SECONDS*SAMPLING_RATE] \n",
    "#     plot_activity(activity, subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0cde3",
   "metadata": {},
   "source": [
    "# Encoding the labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e7c2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column name of the label vector\n",
    "LABEL = 'ActivityEncoded'\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Add a new column to the existing DataFrame with the encoded values\n",
    "df[LABEL] = le.fit_transform(df['label'].values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9218f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get only relevant subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a29b8de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#These are the indexes of the relevant subjects, see FILES\n",
    "indexes = [1,2,7,8,9,13,14,15,16,17]\n",
    "subjects = [FILES[x] for x in indexes]\n",
    "\n",
    "#new dataframe with only the horses in subjects\n",
    "df = df[df['filename'].isin(subjects)]\n",
    "\n",
    "#Might need to add Viva later on again?\n",
    "subject_names = ['Galoway', 'Patron', 'Happy', 'Driekus']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3b165",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Splitting in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a3561be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "  Function to split train and test data by subject\n",
    "  df = dataframe\n",
    "  name = subject to put in test subset\n",
    "  '''\n",
    "def splitBySubject(name):\n",
    "    print(name)\n",
    "    test = df[df['filename'].str.contains(name)]\n",
    "    train = df[~df['filename'].str.contains(name)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1b2e3",
   "metadata": {},
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dd9cad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def featureScaling(data):\n",
    "    train_x_max = data['Ax'].max()\n",
    "    train_y_max = data['Ay'].max()\n",
    "    train_z_max = data['Az'].max()\n",
    "\n",
    "    train_gx_max = data['Gx'].max()\n",
    "    train_gy_max = data['Gy'].max()\n",
    "    train_gz_max = data['Gz'].max()\n",
    "\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    #divide all 3 axis with the max value in the training set\n",
    "    data['Ax'] = data['Ax'] / train_x_max\n",
    "    data['Ay'] = data['Ay'] / train_y_max\n",
    "    data['Az'] = data['Az'] / train_z_max\n",
    "\n",
    "    data['Gx'] = data['Ax'] / train_gx_max\n",
    "    data['Gy'] = data['Ay'] / train_gy_max\n",
    "    data['Gz'] = data['Az'] / train_gz_max\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75bbdcd",
   "metadata": {},
   "source": [
    "# Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7233eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWindows(df, time_steps, step, label_name):\n",
    "    N_FEATURES = 6\n",
    "    windows = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df)-time_steps, step):\n",
    "        axs = df['Ax'].values[i: i + time_steps]\n",
    "        ays = df['Ay'].values[i: i + time_steps]\n",
    "        azs = df['Az'].values[i: i + time_steps]\n",
    "\n",
    "        gxs = df['Gx'].values[i: i + time_steps]\n",
    "        gys = df['Gy'].values[i: i + time_steps]\n",
    "        gzs = df['Gz'].values[i: i + time_steps]\n",
    "        # Retrieve the most often used label in this segment\n",
    "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "        windows.append([axs, ays, azs, gxs, gys, gzs])\n",
    "        labels.append(label)\n",
    "    # Bring the segments into a better shape\n",
    "    reshaped_windows = np.asarray(windows, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return reshaped_windows, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2b410",
   "metadata": {},
   "source": [
    "# Reshaping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db70e30f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reshaping one dimentional xtrain into fitted data for the classifier\n",
    "def inputShape(data):\n",
    "    data = data.reshape(data.shape[0], input_shape)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ad2bb",
   "metadata": {},
   "source": [
    "# OneHotCoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec3d8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying one hot coding to y_train\n",
    "def oneHotCoding(data):\n",
    "    y_train_hot = np_utils.to_categorical(data, num_classes)\n",
    "    return y_train_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9cd0bb",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08ad10e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifierModel():\n",
    "    model_m = Sequential()\n",
    "    # Remark: since coreml cannot accept vector shapes of complex shape like\n",
    "    # [80,3] this workaround is used in order to reshape the vector internally\n",
    "    # prior feeding it into the network\n",
    "    model_m.add(Reshape((TIME_PERIODS, 6), input_shape=(input_shape,)))\n",
    "    model_m.add(Dense(100, activation='relu'))\n",
    "    model_m.add(Dense(100, activation='relu'))\n",
    "    model_m.add(Dense(100, activation='relu'))\n",
    "    model_m.add(Flatten())\n",
    "    model_m.add(Dense(num_classes, activation='softmax'))\n",
    "    return model_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac4373aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "BATCH_SIZE = 600\n",
    "EPOCHS = 2\n",
    "    \n",
    "# takes x_train and y_train_hot\n",
    "def classifier(xdata, ydata):\n",
    "    modelm = classifierModel()\n",
    "\n",
    "    callbacks_list = [\n",
    "        keras.callbacks.EarlyStopping(monitor='accuracy', patience=1)\n",
    "    ]\n",
    "\n",
    "    modelm.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
    "    history = modelm.fit(xdata,\n",
    "                          ydata,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          epochs=EPOCHS,\n",
    "                          callbacks=callbacks_list,\n",
    "                          validation_split=0.2,\n",
    "                          verbose=1)\n",
    "    return history, modelm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c347cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#printing the evaluation results of the train dataset\n",
    "def printResults(history, modelm, x_train, y_train):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(history.history['accuracy'], 'r', label='Accuracy of training data')\n",
    "    plt.plot(history.history['val_accuracy'], 'b', label='Accuracy of validation data')\n",
    "    plt.plot(history.history['loss'], 'r--', label='Loss of training data')\n",
    "    plt.plot(history.history['val_loss'], 'b--', label='Loss of validation data')\n",
    "    plt.title('Model Accuracy and Loss')\n",
    "    plt.ylabel('Accuracy and Loss')\n",
    "    plt.xlabel('Training Epoch')\n",
    "    plt.ylim(0)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Print confusion matrix for training data\n",
    "    y_pred_train = modelm.predict(x_train)\n",
    "    # Take the class with the highest probability from the train predictions\n",
    "    max_y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "    print(classification_report(y_train, max_y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a56589ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the evaluation results of the test dataset\n",
    "def testModel(test, modelm):\n",
    "    # Normalize features for training data set\n",
    "    test['Ax'] = test['Ax'] / test['Ax'].max()\n",
    "    test['Ay'] = test['Ay'] / test['Ay'].max()\n",
    "    test['Az'] = test['Az'] / test['Az'].max()\n",
    "\n",
    "    test['Gx'] = test['Gx'] / test['Gx'].max()\n",
    "    test['Gy'] = test['Gy'] / test['Gy'].max()\n",
    "    test['Gz'] = test['Gz'] / test['Gz'].max()\n",
    "\n",
    "    x_test, y_test = createWindows(test,\n",
    "                                   TIME_PERIODS,\n",
    "                                   STEP_DISTANCE,\n",
    "                                   LABEL)\n",
    "    \n",
    "    # Set input_shape / reshape for Keras\n",
    "    x_test = x_test.reshape(x_test.shape[0], input_shape)\n",
    "\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "\n",
    "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    return x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b020279d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix(validations, predictions, model_m, test):\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(matrix,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=LABELS,\n",
    "                yticklabels=LABELS,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "    y_pred_test = model_m.predict(x_test)\n",
    "    # Take the class with the highest probability from the test predictions\n",
    "    max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "    max_y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    \n",
    "    precision_per_class, recall_per_class, f_score_per_class, _ = metrics.precision_recall_fscore_support(max_y_test, max_y_pred_test, zero_division=0)\n",
    "    _, recall_avg, f_score_avg, _ = metrics.precision_recall_fscore_support(max_y_test, max_y_pred_test, pos_label=None, average=\"weighted\", zero_division=0)\n",
    "    mcc = metrics.matthews_corrcoef(max_y_test, max_y_pred_test)\n",
    "    accuracy = metrics.balanced_accuracy_score(max_y_test, max_y_pred_test)\n",
    "    \n",
    "    print('\\nAccuracy on test data: %0.2f' % accuracy)\n",
    "    \n",
    "    #print(classification_report(max_y_test, max_y_pred_test, output_dict=True))\n",
    "    return matrix, precision_per_class, recall_per_class, f_score_per_class, recall_avg, f_score_avg, mcc, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31dedd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_key = '5109de74-d829-490c-bc62-5713b442fd60'\n",
    "query = Experiment.select().where(Experiment.key == experiment_key).dicts()\n",
    "\n",
    "conf_matrix = []\n",
    "#query = Experiment.select().dicts()\n",
    "for q in query:\n",
    "    conf_matrix = q\n",
    "\n",
    "#query = Activity.select().dicts()\n",
    "#for q in query:\n",
    "#    print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278864ea",
   "metadata": {},
   "source": [
    "# Converting bytearray to confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73e3906e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9841eb060837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#The new_matrix needs to be copied in here from the database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#This is not part of the classifier itself!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'confusion_matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{'confusion_matrix': \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "#The new_matrix needs to be copied in here from the database\n",
    "#This is not part of the classifier itself!\n",
    "if(len(conf_matrix)!=0):\n",
    "    m = conf_matrix.get('confusion_matrix')\n",
    "    m = m.decode()\n",
    "    m = m.replace(\"{'confusion_matrix': \", \"\")\n",
    "    m = m.replace(\"}\", \"\")\n",
    "    m = re.sub(\"\\s+\", \",\", m.strip())\n",
    "    m = m.replace(\"[,\", \"[\")\n",
    "    m = literal_eval(m)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(m,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=LABELS,\n",
    "                yticklabels=LABELS,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b1455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for an experiment and printing its results\n",
    "#insert experiment key below as variable\n",
    "experiment_key = \"4f788d5a-586c-401c-aab2-4778f04780c0\"\n",
    "\n",
    "# query = Experiment.select().where(Activity.key == experiment_key).dicts()\n",
    "# querydf = pd.DataFrame(query)\n",
    "# display(querydf)\n",
    "\n",
    "#query = Experiment.select().where(Experiment.key == experiment_key).dicts()\n",
    "query = Experiment.select().dicts()\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "querydf = pd.DataFrame.from_dict(query)\n",
    "display(querydf)\n",
    "    \n",
    "query = Activity.select().where(Activity.key == experiment_key).dicts()\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "querydf = pd.DataFrame.from_dict(query)\n",
    "display(querydf)\n",
    "    \n",
    "\n",
    "# #selecting queries based on date\n",
    "# query = Experiment.select().where(Experiment.date.day == 3, Experiment.date.month == 5).dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711aa75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model description is NOT included in the parameters\n",
    "PARAMETERS = \"TIME_PERIOD: \" + str(TIME_PERIODS) + \", STEP_DISTANCE: \" + str(STEP_DISTANCE) + \", BATCH_SIZE: \" + str(BATCH_SIZE) + \", EPOCHS: \" + str(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f122d03",
   "metadata": {},
   "source": [
    "# Loop of training with all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = uuid.uuid4()\n",
    "\n",
    "for i in subject_names:\n",
    "    train, test = splitBySubject(i) #splitting the data into test and train datasets\n",
    "    train = featureScaling(train) #feature scaling the train dataset\n",
    "    x_train, y_train = createWindows(train, #windowing the train dataset. Returns the data (x_train) and labels (y_train).\n",
    "                                     TIME_PERIODS, \n",
    "                                     STEP_DISTANCE, \n",
    "                                     LABEL)\n",
    "    x_train, y_train = shuffle(np.array(x_train), np.array(y_train)) #shuffling the train data\n",
    "    num_time_periods, num_sensors = x_train.shape[1], x_train.shape[2]\n",
    "    num_classes = le.classes_.size\n",
    "    input_shape = (num_time_periods*num_sensors)\n",
    "    x_train = inputShape(x_train)\n",
    "    x_train = x_train.astype('float32')\n",
    "    y_train = y_train.astype('float32')\n",
    "    y_train_hot = oneHotCoding(y_train) #encode label Strings to integers\n",
    "    history, modelm = classifier(x_train, y_train_hot) #training the model\n",
    "    #printResults(history, modelm, x_train, y_train) #retrieving and printing the performance results of the training data\n",
    "    x_test, y_test = testModel(test, modelm)\n",
    "    y_pred_test = modelm.predict(x_test)\n",
    "    \n",
    "    # Take the class with the highest probability from the test predictions\n",
    "    max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "    max_y_test = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    matrix, precision_per_class, recall_per_class, f_score_per_class, recall_avg, f_score_avg, mcc_score, acc = show_confusion_matrix(max_y_test, max_y_pred_test, modelm, test) #print confusion matrix and get evaluation results of the test data\n",
    "    \n",
    "    experiment_accuracy = 0\n",
    "    \n",
    "    for act in LABELS:\n",
    "        index = LABELS.index(act)\n",
    "        if(index >= len(matrix)): #activity contains no data\n",
    "            break\n",
    "        TP = matrix[index][index]\n",
    "        FN = matrix[index].sum() - TP\n",
    "        FP = 0\n",
    "        for j in range(0, len(matrix)):\n",
    "            FP += matrix[j][index]\n",
    "        FP = FP - TP\n",
    "        TN = matrix.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "        \n",
    "        experiment_accuracy += accuracy * (TP+FN)/(TP+TN+FP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        #save results per activity per horse in the database\n",
    "        Activity.create(key=uid, test_horse=i, activity=act, accuracy_activity=accuracy, recall_activity=recall_per_class[index], specificity=specificity, precision=precision_per_class[index], TP=TP, TN=TN, FP=FP, FN=FN)\n",
    "        \n",
    "    Experiment.create(key=uid, username=name, test_horse=i, date=date.today(), accuracy_experiment=experiment_accuracy, fscore=f_score_avg, mcc=mcc_score, recall=recall_avg, confusion_matrix=matrix, parameters=PARAMETERS, description=DESCRIPTION) #save results per horse on database\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c402f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313d688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
