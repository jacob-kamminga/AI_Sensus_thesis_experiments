{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instrumental-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "above-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some styling\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "sns.set()\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#Label encoder used to get a numeric representation of a label\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#The activities\n",
    "LABELS = ['standing',\n",
    "          'walking-natural',\n",
    "          'walking-rider',\n",
    "          'trotting-natural',\n",
    "          'trotting-rider',\n",
    "          'running-natural',\n",
    "          'running-rider',\n",
    "          'jumping',\n",
    "          'grazing',\n",
    "          'eating',\n",
    "          'head shake',\n",
    "          'shaking',\n",
    "          'scratch-biting',\n",
    "          'rubbing',\n",
    "          'fighting',\n",
    "          'rolling',\n",
    "          'scared']\n",
    "\n",
    "#Sliding windows\n",
    "TIME_PERIODS = 80\n",
    "STEP_DISTANCE = 40\n",
    "\n",
    "#Datasets\n",
    "FILES = sorted(glob.glob('Data/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-blast",
   "metadata": {},
   "source": [
    "# Set up dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "behavioral-model",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ax</th>\n",
       "      <th>Ay</th>\n",
       "      <th>Az</th>\n",
       "      <th>Gx</th>\n",
       "      <th>Gy</th>\n",
       "      <th>Gz</th>\n",
       "      <th>datetime</th>\n",
       "      <th>label</th>\n",
       "      <th>segment</th>\n",
       "      <th>filename</th>\n",
       "      <th>ActivityEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>54.2</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>2018-06-14 20:06:48.0988</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>58.2</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>2018-06-14 20:06:48.1088</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>26.2</td>\n",
       "      <td>60.6</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>2018-06-14 20:06:48.1188</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>48.7</td>\n",
       "      <td>58.9</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>2018-06-14 20:06:48.1288</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.4</td>\n",
       "      <td>-9.1</td>\n",
       "      <td>2018-06-14 20:06:48.1388</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>60.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>2018-06-14 20:06:48.1488</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>50.8</td>\n",
       "      <td>44.5</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>2018-06-14 20:06:48.1588</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>31.4</td>\n",
       "      <td>42.3</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>2018-06-14 20:06:48.1688</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>43.5</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>2018-06-14 20:06:48.1788</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-18.1</td>\n",
       "      <td>48.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2018-06-14 20:06:48.1888</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ax   Ay  Az    Gx   Gy   Gz                  datetime            label  \\\n",
       "0 6.5 -1.2 3.3 -12.8 54.2 -3.4  2018-06-14 20:06:48.0988  walking-natural   \n",
       "1 6.6 -0.5 3.2   1.7 58.2 -6.8  2018-06-14 20:06:48.1088  walking-natural   \n",
       "2 6.7  0.8 3.5  26.2 60.6 -8.1  2018-06-14 20:06:48.1188  walking-natural   \n",
       "3 6.8  2.1 3.8  48.7 58.9 -8.8  2018-06-14 20:06:48.1288  walking-natural   \n",
       "4 6.8  3.2 4.2  60.0 55.4 -9.1  2018-06-14 20:06:48.1388  walking-natural   \n",
       "5 6.8  3.9 4.7  60.2 50.0 -8.2  2018-06-14 20:06:48.1488  walking-natural   \n",
       "6 6.7  3.5 5.3  50.8 44.5 -6.9  2018-06-14 20:06:48.1588  walking-natural   \n",
       "7 7.2  2.6 5.1  31.4 42.3 -4.8  2018-06-14 20:06:48.1688  walking-natural   \n",
       "8 7.6  1.6 4.3   2.9 43.5 -2.3  2018-06-14 20:06:48.1788  walking-natural   \n",
       "9 7.7  0.8 4.0 -18.1 48.6  1.5  2018-06-14 20:06:48.1888  walking-natural   \n",
       "\n",
       "   segment                           filename  ActivityEncoded  \n",
       "0    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "1    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "2    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "3    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "4    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "5    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "6    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "7    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "8    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "9    13935  Data/subject_11_Patron_part_1.csv               16  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REMOVE_COLUMNS = ['Mx', 'My', 'Mz','A3D','G3D','M3D'] #Add columns to drop from dataframe\n",
    "\n",
    "def loadDataFrame(files):\n",
    "    \"\"\"\n",
    "    Simple function to set up dataframe and initial clean-up of the data\n",
    "    files: path to files\n",
    "    returns: combined dataframe of all files\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        csv = pd.read_csv(file)\n",
    "        csv['filename']=file\n",
    "        df = df.append(csv)\n",
    "        \n",
    "    df.drop(REMOVE_COLUMNS, axis=1, inplace=True)\n",
    "    df['ActivityEncoded'] = le.fit_transform(df['label'].values.ravel())\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_to_float(x):\n",
    "\n",
    "    try:\n",
    "        return np.float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "df = loadDataFrame(FILES)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-lighter",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot data composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-bangkok",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Training examples per activity type\n",
    "df['label'].value_counts().plot(kind='bar', title='Training Examples of subject Viva by Activity Type')\n",
    "plt.show()\n",
    "\n",
    "SECONDS = 10 #nr of seconds to display accelerometer data\n",
    "SAMPLING_RATE = 20 #the sampling rate at which data was recorded\n",
    "\n",
    "def plot_activity(activity, data):\n",
    "\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, figsize=(15, 10), sharex=True)\n",
    "    plot_axis(ax0, data['datetime'], data['Ax'], 'X-Axis')\n",
    "    plot_axis(ax1, data['datetime'], data['Ay'], 'Y-Axis')\n",
    "    plot_axis(ax2, data['datetime'], data['Az'], 'Z-Axis')\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    fig.suptitle(activity)\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    plt.show()\n",
    "\n",
    "def plot_axis(ax, x, y, title):\n",
    "\n",
    "    ax.plot(x, y, 'r')\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\n",
    "    ax.set_xlim([min(x), max(x)])\n",
    "    ax.grid(True)\n",
    "\n",
    "#plot all 3 subplots for each activity\n",
    "for activity in np.unique(df['label']):\n",
    "    subset = df[df['label'] == activity][:SECONDS*SAMPLING_RATE] \n",
    "    plot_activity(activity, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "critical-gnome",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #allfiles = glob.glob('Data/*.csv')\n",
    "# #print(allfiles)\n",
    "# #df = pd.concat((pd.read_data(f) for f in allfiles), ignore_index=True)\n",
    "\n",
    "# df = pd.concat((read_data(f) for f in glob.glob('Data/*')), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecological-animal",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10763567"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "smoking-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the data\n",
    "# show_basic_dataframe_info(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-tennessee",
   "metadata": {},
   "source": [
    "# PRE PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-attention",
   "metadata": {},
   "source": [
    "- Make all the elements float if they need be\n",
    "- Shuffle data frame\n",
    "- Split to test and train set\n",
    "- Normalize to a range\n",
    "- TODO segment\n",
    "- TODO balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-alignment",
   "metadata": {},
   "source": [
    "# Get only relevant subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "funny-livestock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test: ['Data/subject_11_Patron_part_1.csv' 'Data/subject_11_Patron_part_2.csv']\n",
      "Train horses ['Data/subject_8_Galoway_part_1.csv' 'Data/subject_8_Galoway_part_2.csv'\n",
      " 'Data/subject_8_Galoway_part_3.csv' 'Data/subject_14_Bacardi_part_1.csv'\n",
      " 'Data/subject_7_Driekus_part_1.csv' 'Data/subject_7_Driekus_part_2.csv'\n",
      " 'Data/subject_2_Happy_part_1.csv' 'Data/subject_2_Happy_part_2.csv'\n",
      " 'Data/subject_2_Happy_part_3.csv']\n",
      "\n",
      "\n",
      "Test: ['Data/subject_8_Galoway_part_1.csv' 'Data/subject_8_Galoway_part_2.csv'\n",
      " 'Data/subject_8_Galoway_part_3.csv']\n",
      "Train horses ['Data/subject_11_Patron_part_1.csv' 'Data/subject_11_Patron_part_2.csv'\n",
      " 'Data/subject_14_Bacardi_part_1.csv' 'Data/subject_7_Driekus_part_1.csv'\n",
      " 'Data/subject_7_Driekus_part_2.csv' 'Data/subject_2_Happy_part_1.csv'\n",
      " 'Data/subject_2_Happy_part_2.csv' 'Data/subject_2_Happy_part_3.csv']\n",
      "\n",
      "\n",
      "Test: ['Data/subject_14_Bacardi_part_1.csv']\n",
      "Train horses ['Data/subject_11_Patron_part_1.csv' 'Data/subject_11_Patron_part_2.csv'\n",
      " 'Data/subject_8_Galoway_part_1.csv' 'Data/subject_8_Galoway_part_2.csv'\n",
      " 'Data/subject_8_Galoway_part_3.csv' 'Data/subject_7_Driekus_part_1.csv'\n",
      " 'Data/subject_7_Driekus_part_2.csv' 'Data/subject_2_Happy_part_1.csv'\n",
      " 'Data/subject_2_Happy_part_2.csv' 'Data/subject_2_Happy_part_3.csv']\n",
      "\n",
      "\n",
      "Test: ['Data/subject_7_Driekus_part_1.csv' 'Data/subject_7_Driekus_part_2.csv']\n",
      "Train horses ['Data/subject_11_Patron_part_1.csv' 'Data/subject_11_Patron_part_2.csv'\n",
      " 'Data/subject_8_Galoway_part_1.csv' 'Data/subject_8_Galoway_part_2.csv'\n",
      " 'Data/subject_8_Galoway_part_3.csv' 'Data/subject_14_Bacardi_part_1.csv'\n",
      " 'Data/subject_2_Happy_part_1.csv' 'Data/subject_2_Happy_part_2.csv'\n",
      " 'Data/subject_2_Happy_part_3.csv']\n",
      "\n",
      "\n",
      "Test: ['Data/subject_2_Happy_part_1.csv' 'Data/subject_2_Happy_part_2.csv'\n",
      " 'Data/subject_2_Happy_part_3.csv']\n",
      "Train horses ['Data/subject_11_Patron_part_1.csv' 'Data/subject_11_Patron_part_2.csv'\n",
      " 'Data/subject_8_Galoway_part_1.csv' 'Data/subject_8_Galoway_part_2.csv'\n",
      " 'Data/subject_8_Galoway_part_3.csv' 'Data/subject_14_Bacardi_part_1.csv'\n",
      " 'Data/subject_7_Driekus_part_1.csv' 'Data/subject_7_Driekus_part_2.csv']\n"
     ]
    }
   ],
   "source": [
    "#Splitting the subjects on name and file\n",
    "subjects = df.groupby(df.filename)\n",
    "\n",
    "# csv files from relevant subjects\n",
    "csv11 = [subjects.get_group('Data/subject_11_Patron_part_1.csv'), subjects.get_group('Data/subject_11_Patron_part_2.csv')]\n",
    "csv8 = [subjects.get_group('Data/subject_8_Galoway_part_1.csv'), subjects.get_group('Data/subject_8_Galoway_part_2.csv'), subjects.get_group('Data/subject_8_Galoway_part_3.csv')]\n",
    "csv14 = [subjects.get_group('Data/subject_14_Bacardi_part_1.csv')]\n",
    "csv7 = [subjects.get_group('Data/subject_7_Driekus_part_1.csv'), subjects.get_group('Data/subject_7_Driekus_part_2.csv')]\n",
    "csv2 = [subjects.get_group('Data/subject_2_Happy_part_1.csv'), subjects.get_group('Data/subject_2_Happy_part_2.csv'), subjects.get_group('Data/subject_2_Happy_part_3.csv')]\n",
    "\n",
    "# Create 1 dataframe for each relevant subject\n",
    "patron = pd.concat(csv11)\n",
    "galoway = pd.concat(csv8)\n",
    "bacardi = pd.concat(csv14)\n",
    "driekus = pd.concat(csv7)\n",
    "happy = pd.concat(csv2)\n",
    "\n",
    "\n",
    "indexes = [0,1,2,3,4]\n",
    "\n",
    "horses = [patron, galoway, bacardi, driekus, happy]\n",
    "\n",
    "# Splitting test and trainig sets    \n",
    "for num in indexes:\n",
    "    \n",
    "    test_horse = horses[num]\n",
    "    others = horses[:num]\n",
    "    others.extend(horses[num+1:])\n",
    "    train_horses = pd.concat(others)\n",
    "    \n",
    "    print(f\"\\n\\nTest: {test_horse['filename'].unique()}\")\n",
    "    \n",
    "    print(f\"Train horses {train_horses['filename'].unique()}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-collar",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the whole dataframe\n",
    "def shuffle(data_frame):\n",
    "    return data_frame.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-cooperation",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-straight",
   "metadata": {},
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide all 3 axis with the max value in the training set\n",
    "train['Ax'] = train['Ax'] / train['Ax'].max()\n",
    "train['Ay'] = train['Ay'] / train['Ay'].max()\n",
    "train['Az'] = train['Az'] / train['Az'].max()\n",
    "\n",
    "#divide all 3 axis with the max value in the training set\n",
    "test['Ax'] = train['Ax'] / train['Ax'].max()\n",
    "test['Ay'] = train['Ay'] / train['Ay'].max()\n",
    "test['Az'] = train['Az'] / train['Az'].max()\n",
    "\n",
    "\n",
    "\n",
    "# Round numbers up to 5 decimal spaces\n",
    "train = train.round({'Ax': 5, 'Ay': 5, 'Az': 5})\n",
    "test = test.round({'Ax': 5, 'Ay': 5, 'Az': 5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-youth",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'ActivityEncoded'\n",
    "\n",
    "def create_segments_and_labels(df, time_steps, step, label_name):\n",
    "\n",
    "    # x, y, z acceleration as features\n",
    "    N_FEATURES = 3\n",
    "    # Number of steps to advance in each iteration (for me, it should always\n",
    "    # be equal to the time_steps in order to have no overlap between segments)\n",
    "    # step = time_steps\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['Ax'].values[i: i + time_steps]\n",
    "        ys = df['Ay'].values[i: i + time_steps]\n",
    "        zs = df['Az'].values[i: i + time_steps]\n",
    "        # Retrieve the most often used label in this segment\n",
    "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "        segments.append([xs, ys, zs])\n",
    "        labels.append(label)\n",
    "\n",
    "    # Bring the segments into a better shape\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return reshaped_segments, labels\n",
    "\n",
    "x_train, y_train = create_segments_and_labels(train, TIME_PERIODS, STEP_DISTANCE, LABEL)\n",
    "x_test, y_test = create_segments_and_labels(test, TIME_PERIODS, STEP_DISTANCE, LABEL)\n",
    "\n",
    "#set dimension of input and output\n",
    "num_time_periods, num_sensors = x_train.shape[1], x_train.shape[2]\n",
    "num_classes = le.classes_.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-sight",
   "metadata": {},
   "source": [
    "# Flattening to one dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (num_time_periods*num_sensors)\n",
    "x_train = x_train.reshape(x_train.shape[0], input_shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-minneapolis",
   "metadata": {},
   "source": [
    "# Apply one-hot coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-mobility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "float(df['Az'].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "for d in df['Az']:\n",
    "    try:\n",
    "         ds.append(float(d))\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-subscriber",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
