{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "instrumental-beverage",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cebfbb9-558a-4426-fb29-b03d1abc0505"
      },
      "source": [
        "from __future__ import print_function\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "#if youre using google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "instrumental-beverage",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "above-steering"
      },
      "source": [
        "#Some styling\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "sns.set()\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "#Label encoder used to get a numeric representation of a label\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "#The activities\n",
        "LABELS = ['standing',\n",
        "          'walking-natural',\n",
        "          'walking-rider',\n",
        "          'trotting-natural',\n",
        "          'trotting-rider',\n",
        "          'running-natural',\n",
        "          'running-rider',\n",
        "          'jumping',\n",
        "          'grazing',\n",
        "          'eating',\n",
        "          'head shake',\n",
        "          'shaking',\n",
        "          'scratch-biting',\n",
        "          'rubbing',\n",
        "          'fighting',\n",
        "          'rolling',\n",
        "          'scared']\n",
        "\n",
        "#Sliding windows\n",
        "TIME_PERIODS = 80\n",
        "STEP_DISTANCE = 40\n",
        "\n",
        "#Datasets\n",
        "PATH = '/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/'\n",
        "FILES = sorted(glob.glob(PATH + '*.csv'))\n"
      ],
      "id": "above-steering",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gentle-blast"
      },
      "source": [
        "# Set up dataframe"
      ],
      "id": "gentle-blast"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behavioral-model",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "635f095f-41b3-480c-cf84-ed2f4e4c1702"
      },
      "source": [
        "REMOVE_COLUMNS = ['Mx', 'My', 'Mz','A3D','G3D','M3D'] #Add columns to drop from dataframe\n",
        "def loadDataFrame(files):\n",
        "    \"\"\"\n",
        "    Simple function to set up dataframe and initial clean-up of the data\n",
        "    files: path to files\n",
        "    returns: combined dataframe of all files\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    for file in files:\n",
        "        csv = pd.read_csv(file)\n",
        "        csv['filename']= file\n",
        "        df = df.append(csv)\n",
        "        \n",
        "    df.drop(REMOVE_COLUMNS, axis=1, inplace=True)\n",
        "    df['ActivityEncoded'] = le.fit_transform(df['label'].values.ravel())\n",
        "\n",
        "    return df\n",
        "\n",
        "def convert_to_float(x):\n",
        "\n",
        "    try:\n",
        "        return np.float(x)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "\n",
        "df = loadDataFrame(FILES)\n",
        "df.head(10)\n",
        "\n"
      ],
      "id": "behavioral-model",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ax</th>\n",
              "      <th>Ay</th>\n",
              "      <th>Az</th>\n",
              "      <th>Gx</th>\n",
              "      <th>Gy</th>\n",
              "      <th>Gz</th>\n",
              "      <th>datetime</th>\n",
              "      <th>label</th>\n",
              "      <th>segment</th>\n",
              "      <th>filename</th>\n",
              "      <th>ActivityEncoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.5</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>3.3</td>\n",
              "      <td>-12.8</td>\n",
              "      <td>54.2</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>2018-06-14 20:06:48.0988</td>\n",
              "      <td>walking-natural</td>\n",
              "      <td>13935</td>\n",
              "      <td>/content/drive/MyDrive/Bachelor GP/Let there b...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.6</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.7</td>\n",
              "      <td>58.2</td>\n",
              "      <td>-6.8</td>\n",
              "      <td>2018-06-14 20:06:48.1088</td>\n",
              "      <td>walking-natural</td>\n",
              "      <td>13935</td>\n",
              "      <td>/content/drive/MyDrive/Bachelor GP/Let there b...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>3.5</td>\n",
              "      <td>26.2</td>\n",
              "      <td>60.6</td>\n",
              "      <td>-8.1</td>\n",
              "      <td>2018-06-14 20:06:48.1188</td>\n",
              "      <td>walking-natural</td>\n",
              "      <td>13935</td>\n",
              "      <td>/content/drive/MyDrive/Bachelor GP/Let there b...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.8</td>\n",
              "      <td>2.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>48.7</td>\n",
              "      <td>58.9</td>\n",
              "      <td>-8.8</td>\n",
              "      <td>2018-06-14 20:06:48.1288</td>\n",
              "      <td>walking-natural</td>\n",
              "      <td>13935</td>\n",
              "      <td>/content/drive/MyDrive/Bachelor GP/Let there b...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.8</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.2</td>\n",
              "      <td>60.0</td>\n",
              "      <td>55.4</td>\n",
              "      <td>-9.1</td>\n",
              "      <td>2018-06-14 20:06:48.1388</td>\n",
              "      <td>walking-natural</td>\n",
              "      <td>13935</td>\n",
              "      <td>/content/drive/MyDrive/Bachelor GP/Let there b...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.8</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.7</td>\n",
              "      <td>60.2</td>\n",
              "      <td>50.0</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>2018-06-14 20:06:48.1488</td>\n",
              "      <td>walking-natural</td>\n",
              "      <td>13935</td>\n",
              "      <td>/content/drive/MyDrive/Bachelor GP/Let there b...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5.3</td>\n",
              "      <td>50.8</td>\n",
              "      <td>44.5</td>\n",
              "      <td>-6.9</td>\n",
              "      <td>2018-06-14 20:06:48.1588</td>\n",
              "      <td>walking-natural</td>\n",
              "      <td>13935</td>\n",
              "      <td>/content/drive/MyDrive/Bachelor GP/Let there b...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.2</td>\n",
              "      <td>2.6</td>\n",
              "      <td>5.1</td>\n",
              "      <td>31.4</td>\n",
              "      <td>42.3</td>\n",
              "      <td>-4.8</td>\n",
              "      <td>2018-06-14 20:06:48.1688</td>\n",
              "      <td>walking-natural</td>\n",
              "      <td>13935</td>\n",
              "      <td>/content/drive/MyDrive/Bachelor GP/Let there b...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.6</td>\n",
              "      <td>1.6</td>\n",
              "      <td>4.3</td>\n",
              "      <td>2.9</td>\n",
              "      <td>43.5</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>2018-06-14 20:06:48.1788</td>\n",
              "      <td>walking-natural</td>\n",
              "      <td>13935</td>\n",
              "      <td>/content/drive/MyDrive/Bachelor GP/Let there b...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-18.1</td>\n",
              "      <td>48.6</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2018-06-14 20:06:48.1888</td>\n",
              "      <td>walking-natural</td>\n",
              "      <td>13935</td>\n",
              "      <td>/content/drive/MyDrive/Bachelor GP/Let there b...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Ax   Ay  ...                                           filename  ActivityEncoded\n",
              "0 6.5 -1.2  ...  /content/drive/MyDrive/Bachelor GP/Let there b...               16\n",
              "1 6.6 -0.5  ...  /content/drive/MyDrive/Bachelor GP/Let there b...               16\n",
              "2 6.7  0.8  ...  /content/drive/MyDrive/Bachelor GP/Let there b...               16\n",
              "3 6.8  2.1  ...  /content/drive/MyDrive/Bachelor GP/Let there b...               16\n",
              "4 6.8  3.2  ...  /content/drive/MyDrive/Bachelor GP/Let there b...               16\n",
              "5 6.8  3.9  ...  /content/drive/MyDrive/Bachelor GP/Let there b...               16\n",
              "6 6.7  3.5  ...  /content/drive/MyDrive/Bachelor GP/Let there b...               16\n",
              "7 7.2  2.6  ...  /content/drive/MyDrive/Bachelor GP/Let there b...               16\n",
              "8 7.6  1.6  ...  /content/drive/MyDrive/Bachelor GP/Let there b...               16\n",
              "9 7.7  0.8  ...  /content/drive/MyDrive/Bachelor GP/Let there b...               16\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "prostate-lighter"
      },
      "source": [
        "# Plot data composition"
      ],
      "id": "prostate-lighter"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "smart-bangkok"
      },
      "source": [
        "\n",
        "#Training examples per activity type\n",
        "df['label'].value_counts().plot(kind='bar', title='Training Examples by Activity Type')\n",
        "plt.show()\n",
        "\n",
        "SECONDS = 10 #nr of seconds to display accelerometer data\n",
        "SAMPLING_RATE = 20 #the sampling rate at which data was recorded\n",
        "\n",
        "def plot_activity(activity, data):\n",
        "\n",
        "    fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, figsize=(15, 10), sharex=True)\n",
        "    plot_axis(ax0, data['datetime'], data['Ax'], 'X-Axis')\n",
        "    plot_axis(ax1, data['datetime'], data['Ay'], 'Y-Axis')\n",
        "    plot_axis(ax2, data['datetime'], data['Az'], 'Z-Axis')\n",
        "    plt.subplots_adjust(hspace=0.2)\n",
        "    fig.suptitle(activity)\n",
        "    plt.subplots_adjust(top=0.90)\n",
        "    plt.show()\n",
        "\n",
        "def plot_axis(ax, x, y, title):\n",
        "\n",
        "    ax.plot(x, y, 'r')\n",
        "    ax.set_title(title)\n",
        "    ax.xaxis.set_visible(False)\n",
        "    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\n",
        "    ax.set_xlim([min(x), max(x)])\n",
        "    ax.grid(True)\n",
        "\n",
        "#plot all 3 subplots for each activity\n",
        "for activity in np.unique(df['label']):\n",
        "    subset = df[df['label'] == activity][:SECONDS*SAMPLING_RATE] \n",
        "    plot_activity(activity, subset)\n"
      ],
      "id": "smart-bangkok",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "distributed-alignment"
      },
      "source": [
        "# Get only relevant subjects"
      ],
      "id": "distributed-alignment"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "funny-livestock"
      },
      "source": [
        "#These are the indexes of the relevant subjects, see FILES\n",
        "indexes = [0,1,2,7,8,9,13,14,15,16,17]\n",
        "subjects = [FILES[x] for x in indexes]\n",
        "\n",
        "#new dataframe with only the horses in subjects\n",
        "df = df[df['filename'].isin(subjects)]\n"
      ],
      "id": "funny-livestock",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvCWSfKwbhYI"
      },
      "source": [
        "#Split the data"
      ],
      "id": "vvCWSfKwbhYI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIxFJXR6bkof",
        "outputId": "dfcfa258-6505-43ea-b381-7cdd186fb639",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def splitBySubject(data, name):\n",
        "  '''\n",
        "  Function to split train and test data by subject\n",
        "  data = dataframe\n",
        "  name = subject to put in test subset\n",
        "  '''\n",
        "  test = data[data['filename'].str.contains(name)]\n",
        "  train = data[~data['filename'].str.contains(name)]\n",
        "  return train, test\n",
        "\n",
        "\n",
        "train, test = splitBySubject(df, 'Galoway')\n",
        "\n",
        "print(train['filename'].unique())\n",
        "print(test['filename']. unique())"
      ],
      "id": "RIxFJXR6bkof",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/subject_11_Patron_part_1.csv'\n",
            " '/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/subject_11_Patron_part_2.csv'\n",
            " '/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/subject_14_Bacardi_part_1.csv'\n",
            " '/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/subject_2_Happy_part_1.csv'\n",
            " '/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/subject_2_Happy_part_2.csv'\n",
            " '/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/subject_2_Happy_part_3.csv'\n",
            " '/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/subject_7_Driekus_part_1.csv'\n",
            " '/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/subject_7_Driekus_part_2.csv']\n",
            "['/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/subject_8_Galoway_part_1.csv'\n",
            " '/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/subject_8_Galoway_part_2.csv'\n",
            " '/content/drive/MyDrive/Bachelor GP/Let there be IMU data/datasets/JacobHorse/subject_8_Galoway_part_3.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "measured-collar"
      },
      "source": [
        "# Shuffle data"
      ],
      "id": "measured-collar"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "southwest-briefing"
      },
      "source": [
        "def shuffle(data_frame):\n",
        "    return data_frame.sample(frac=1).reset_index(drop=True)\n"
      ],
      "id": "southwest-briefing",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "given-straight"
      },
      "source": [
        "# Feature scaling"
      ],
      "id": "given-straight"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meaning-ocean"
      },
      "source": [
        "#divide all 3 axis with the max value in the training set\n",
        "train['Ax'] = train['Ax'] / train['Ax'].max()\n",
        "train['Ay'] = train['Ay'] / train['Ay'].max()\n",
        "train['Az'] = train['Az'] / train['Az'].max()\n",
        "\n",
        "#divide all 3 axis with the max value in the test set\n",
        "test['Ax'] = test['Ax'] / test['Ax'].max()\n",
        "test['Ay'] = test['Ay'] / test['Ay'].max()\n",
        "test['Az'] = test['Az'] / test['Az'].max()"
      ],
      "id": "meaning-ocean",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "regular-youth"
      },
      "source": [
        "# Segmentation"
      ],
      "id": "regular-youth"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mathematical-honey"
      },
      "source": [
        "LABEL = 'ActivityEncoded'\n",
        "\n",
        "def create_segments_and_labels(df, time_steps, step, label_name):\n",
        "\n",
        "    # x, y, z acceleration as features\n",
        "    N_FEATURES = 3\n",
        "    # Number of steps to advance in each iteration (for me, it should always\n",
        "    # be equal to the time_steps in order to have no overlap between segments)\n",
        "    # step = time_steps\n",
        "    segments = []\n",
        "    labels = []\n",
        "    for i in range(0, len(df) - time_steps, step):\n",
        "        xs = df['Ax'].values[i: i + time_steps]\n",
        "        ys = df['Ay'].values[i: i + time_steps]\n",
        "        zs = df['Az'].values[i: i + time_steps]\n",
        "        # Retrieve the most often used label in this segment\n",
        "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
        "        segments.append([xs, ys, zs])\n",
        "        labels.append(label)\n",
        "\n",
        "    # Bring the segments into a better shape\n",
        "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
        "    labels = np.asarray(labels)\n",
        "\n",
        "    return reshaped_segments, labels\n",
        "\n",
        "x_train, y_train = create_segments_and_labels(train, TIME_PERIODS, STEP_DISTANCE, LABEL)\n",
        "x_test, y_test = create_segments_and_labels(test, TIME_PERIODS, STEP_DISTANCE, LABEL)\n",
        "\n",
        "#set dimension of input and output\n",
        "num_time_periods, num_sensors = x_train.shape[1], x_train.shape[2]\n",
        "num_classes = le.classes_.size"
      ],
      "id": "mathematical-honey",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chemical-sight"
      },
      "source": [
        "# Flattening to one dimention"
      ],
      "id": "chemical-sight"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "portuguese-birmingham"
      },
      "source": [
        "input_shape = (num_time_periods*num_sensors)\n",
        "x_train = x_train.reshape(x_train.shape[0], input_shape)\n",
        "x_test = x_test.reshape(x_test.shape[0], input_shape)"
      ],
      "id": "portuguese-birmingham",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "single-minneapolis"
      },
      "source": [
        "# Apply one-hot coding"
      ],
      "id": "single-minneapolis"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyric-transmission"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)"
      ],
      "id": "lyric-transmission",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ordered-batman"
      },
      "source": [
        "float(df['Az'].head(1))"
      ],
      "id": "ordered-batman",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "disturbed-stone"
      },
      "source": [
        "ds = []\n",
        "for d in df['Az']:\n",
        "    try:\n",
        "         ds.append(float(d))\n",
        "    except ValueError:\n",
        "        pass"
      ],
      "id": "disturbed-stone",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35vPEOYkHc_C"
      },
      "source": [
        "#Set up Neural Network"
      ],
      "id": "35vPEOYkHc_C"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lItvzXhBHycO"
      },
      "source": [
        "##model architecture"
      ],
      "id": "lItvzXhBHycO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVR7I7SNHwW3"
      },
      "source": [
        "model_m = Sequential()\n",
        "# Remark: since coreml cannot accept vector shapes of complex shape like\n",
        "# [80,3] this workaround is used in order to reshape the vector internally\n",
        "# prior feeding it into the network\n",
        "model_m.add(Reshape((TIME_PERIODS, 3), input_shape=(input_shape,)))\n",
        "model_m.add(Dense(100, activation='relu'))\n",
        "model_m.add(Dense(100, activation='relu'))\n",
        "model_m.add(Dense(100, activation='relu'))\n",
        "model_m.add(Flatten())\n",
        "model_m.add(Dense(num_classes, activation='softmax'))\n",
        "print(model_m.summary())"
      ],
      "id": "aVR7I7SNHwW3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNGCgUZ-IAuB"
      },
      "source": [
        "##Hyperparameters"
      ],
      "id": "kNGCgUZ-IAuB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jscEShB_IDDV"
      },
      "source": [
        "BATCH_SIZE = 400\n",
        "EPOCHS = 50\n",
        "VALIDATION_SIZE = 0.2"
      ],
      "id": "jscEShB_IDDV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXw92cc2IGF_"
      },
      "source": [
        "#Training the model"
      ],
      "id": "rXw92cc2IGF_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LuE_4UcIK1m"
      },
      "source": [
        "callbacks_list = [\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
        "        monitor='val_loss', save_best_only=True),\n",
        "        keras.callbacks.EarlyStopping(monitor='acc', patience=1)\n",
        "]\n",
        "\n",
        "model_m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model_m.fit(x_train, \n",
        "                      y_train_hot, \n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      epochs=EPOCHS,\n",
        "                      callbacks=callbacks_list,\n",
        "                      validation_split=VALIDATION_SIZE,\n",
        "                      verbose=1)"
      ],
      "id": "0LuE_4UcIK1m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0W1RB60IqGP"
      },
      "source": [
        "#Check performance on test data"
      ],
      "id": "i0W1RB60IqGP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVr2Vk1rIt72"
      },
      "source": [
        "def show_confusion_matrix(validations, predictions):\n",
        "\n",
        "    matrix = metrics.confusion_matrix(validations, predictions)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(matrix,\n",
        "                cmap='coolwarm',\n",
        "                linecolor='white',\n",
        "                linewidths=1,\n",
        "                xticklabels=LABELS,\n",
        "                yticklabels=LABELS,\n",
        "                annot=True,\n",
        "                fmt='d')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "y_pred_test = model_m.predict(x_test)\n",
        "\n",
        "# Take the class with the highest probability from the test predictions\n",
        "max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
        "\n",
        "\n",
        "max_y_test = np.argmax(y_test_hot, axis=1)\n",
        "\n",
        "show_confusion_matrix(max_y_test, max_y_pred_test)\n",
        "\n",
        "print(classification_report(max_y_test, max_y_pred_test))"
      ],
      "id": "iVr2Vk1rIt72",
      "execution_count": null,
      "outputs": []
    }
  ]
}