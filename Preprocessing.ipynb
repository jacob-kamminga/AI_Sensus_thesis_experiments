{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L0RVm4jf45P"
      },
      "source": [
        "#Importing libraries"
      ],
      "id": "-L0RVm4jf45P"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "secret-bolivia"
      },
      "source": [
        "from __future__ import print_function\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import sklearn as skl\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#file management\n",
        "import glob\n",
        "import os"
      ],
      "id": "secret-bolivia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziut1GKSf99z"
      },
      "source": [
        "Setting up some constants"
      ],
      "id": "ziut1GKSf99z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "central-atmosphere"
      },
      "source": [
        "#Some styling\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "sns.set()\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "#Label encoder used to get a numeric representation of a label\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "#The activities\n",
        "LABELS = ['standing',\n",
        "          'walking-natural',\n",
        "          'walking-rider',\n",
        "          'trotting-natural',\n",
        "          'trotting-rider',\n",
        "          'running-natural',\n",
        "          'running-rider',\n",
        "          'jumping',\n",
        "          'grazing',\n",
        "          'eating',\n",
        "          'head shake',\n",
        "          'shaking',\n",
        "          'scratch-biting',\n",
        "          'rubbing',\n",
        "          'fighting',\n",
        "          'rolling',\n",
        "          'scared']\n",
        "\n",
        "#Sliding windows\n",
        "TIME_PERIODS = 80\n",
        "STEP_DISTANCE = 40\n",
        "\n",
        "#Datasets\n",
        "FILES = sorted(glob.glob('horse_data/*.csv'))"
      ],
      "id": "central-atmosphere",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH1YU1NYgGMs"
      },
      "source": [
        "#Set up dataframe"
      ],
      "id": "jH1YU1NYgGMs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sacred-liquid"
      },
      "source": [
        "REMOVE_COLUMNS = ['Mx', 'My', 'Mz','A3D','G3D','M3D'] #Add columns to drop from dataframe\n",
        "\n",
        "def loadDataFrame(files):\n",
        "    \"\"\"\n",
        "    Simple function to set up dataframe and initial clean-up of the data\n",
        "    files: path to files\n",
        "    returns: combined dataframe of all files\n",
        "    \"\"\"\n",
        "    df = pd.concat((pd.read_csv(file) for file in files))\n",
        "    df.drop(REMOVE_COLUMNS, axis=1, inplace=True)\n",
        "    df['ActivityEncoded'] = le.fit_transform(df['label'].values.ravel())\n",
        "    return df\n",
        "\n",
        "def convert_to_float(x):\n",
        "\n",
        "    try:\n",
        "        return np.float(x)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "\n",
        "df = loadDataFrame(FILES)\n",
        "df.head(10)"
      ],
      "id": "sacred-liquid",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwERs3VbgRRb"
      },
      "source": [
        "#Plot data composition"
      ],
      "id": "SwERs3VbgRRb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sguQ5OymgXUz"
      },
      "source": [
        "#Training examples per activity type\r\n",
        "df['label'].value_counts().plot(kind='bar', title='Training Examples of subject Viva by Activity Type')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "SECONDS = 10 #nr of seconds to display accelerometer data\r\n",
        "SAMPLING_RATE = 20 #the sampling rate at which data was recorded\r\n",
        "\r\n",
        "def plot_activity(activity, data):\r\n",
        "\r\n",
        "    fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, figsize=(15, 10), sharex=True)\r\n",
        "    plot_axis(ax0, data['datetime'], data['Ax'], 'X-Axis')\r\n",
        "    plot_axis(ax1, data['datetime'], data['Ay'], 'Y-Axis')\r\n",
        "    plot_axis(ax2, data['datetime'], data['Az'], 'Z-Axis')\r\n",
        "    plt.subplots_adjust(hspace=0.2)\r\n",
        "    fig.suptitle(activity)\r\n",
        "    plt.subplots_adjust(top=0.90)\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "def plot_axis(ax, x, y, title):\r\n",
        "\r\n",
        "    ax.plot(x, y, 'r')\r\n",
        "    ax.set_title(title)\r\n",
        "    ax.xaxis.set_visible(False)\r\n",
        "    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\r\n",
        "    ax.set_xlim([min(x), max(x)])\r\n",
        "    ax.grid(True)\r\n",
        "\r\n",
        "#plot all 3 subplots for each activity\r\n",
        "for activity in np.unique(df['label']):\r\n",
        "    subset = df[df['label'] == activity][:SECONDS*SAMPLING_RATE] \r\n",
        "    plot_activity(activity, subset)\r\n"
      ],
      "id": "sguQ5OymgXUz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDjrSeB0gdJ1"
      },
      "source": [
        "#Split training and test set"
      ],
      "id": "MDjrSeB0gdJ1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sedaCsnegipH"
      },
      "source": [
        "#Shuffles and splits the data into a training set of 80% of the data and a test set containing the other 20%\r\n",
        "train, test = skl.model_selection.train_test_split(df, test_size=0.2, random_state=42, shuffle=True)"
      ],
      "id": "sedaCsnegipH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpYP16_DgoDz"
      },
      "source": [
        "#Apply feature scaling"
      ],
      "id": "KpYP16_DgoDz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKPEu5O5gqcb"
      },
      "source": [
        "#divide all 3 axis with the max value in the training set\r\n",
        "train['Ax'] = train['Ax'] / train['Ax'].max()\r\n",
        "train['Ay'] = train['Ay'] / train['Ay'].max()\r\n",
        "train['Az'] = train['Az'] / train['Az'].max()\r\n",
        "\r\n",
        "#divide all 3 axis with the max value in the training set\r\n",
        "test['Ax'] = train['Ax'] / train['Ax'].max()\r\n",
        "test['Ay'] = train['Ay'] / train['Ay'].max()\r\n",
        "test['Az'] = train['Az'] / train['Az'].max()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Round numbers up to 5 decimal spaces\r\n",
        "train = train.round({'Ax': 5, 'Ay': 5, 'Az': 5})\r\n",
        "test = test.round({'Ax': 5, 'Ay': 5, 'Az': 5})"
      ],
      "id": "EKPEu5O5gqcb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJZC9109gvyz"
      },
      "source": [
        "#Segmentation of data (Sliding windows)"
      ],
      "id": "DJZC9109gvyz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7a3bjWeg25F"
      },
      "source": [
        "LABEL = 'ActivityEncoded'\r\n",
        "\r\n",
        "def create_segments_and_labels(df, time_steps, step, label_name):\r\n",
        "\r\n",
        "    # x, y, z acceleration as features\r\n",
        "    N_FEATURES = 3\r\n",
        "    # Number of steps to advance in each iteration (for me, it should always\r\n",
        "    # be equal to the time_steps in order to have no overlap between segments)\r\n",
        "    # step = time_steps\r\n",
        "    segments = []\r\n",
        "    labels = []\r\n",
        "    for i in range(0, len(df) - time_steps, step):\r\n",
        "        xs = df['Ax'].values[i: i + time_steps]\r\n",
        "        ys = df['Ay'].values[i: i + time_steps]\r\n",
        "        zs = df['Az'].values[i: i + time_steps]\r\n",
        "        # Retrieve the most often used label in this segment\r\n",
        "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\r\n",
        "        segments.append([xs, ys, zs])\r\n",
        "        labels.append(label)\r\n",
        "\r\n",
        "    # Bring the segments into a better shape\r\n",
        "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\r\n",
        "    labels = np.asarray(labels)\r\n",
        "\r\n",
        "    return reshaped_segments, labels\r\n",
        "\r\n",
        "x_train, y_train = create_segments_and_labels(train, TIME_PERIODS, STEP_DISTANCE, LABEL)\r\n",
        "x_test, y_test = create_segments_and_labels(test, TIME_PERIODS, STEP_DISTANCE, LABEL)\r\n",
        "\r\n",
        "#set dimension of input and output\r\n",
        "num_time_periods, num_sensors = x_train.shape[1], x_train.shape[2]\r\n",
        "num_classes = le.classes_.size"
      ],
      "id": "K7a3bjWeg25F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi8EEcQEg5sE"
      },
      "source": [
        "#Flatten data to one dimension"
      ],
      "id": "gi8EEcQEg5sE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMLSZTR_hDC7"
      },
      "source": [
        "input_shape = (num_time_periods*num_sensors)\r\n",
        "x_train = x_train.reshape(x_train.shape[0], input_shape)\r\n",
        "x_test = x_test.reshape(x_test.shape[0], input_shape)"
      ],
      "id": "kMLSZTR_hDC7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiZ_4WiOhIN7"
      },
      "source": [
        "# Apply One-Hot encoding"
      ],
      "id": "ZiZ_4WiOhIN7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-yBKM9whLOr"
      },
      "source": [
        "x_train = x_train.astype('float32')\r\n",
        "y_train = y_train.astype('float32')\r\n",
        "x_test = x_test.astype('float32')\r\n",
        "y_test = y_test.astype('float32')\r\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\r\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)"
      ],
      "id": "0-yBKM9whLOr",
      "execution_count": null,
      "outputs": []
    }
  ]
}