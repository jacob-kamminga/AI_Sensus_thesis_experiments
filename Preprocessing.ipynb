{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "featured-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "final-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some styling\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "sns.set()\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#Label encoder used to get a numeric representation of a label\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#The activities\n",
    "LABELS = ['standing',\n",
    "          'walking-natural',\n",
    "          'walking-rider',\n",
    "          'trotting-natural',\n",
    "          'trotting-rider',\n",
    "          'running-natural',\n",
    "          'running-rider',\n",
    "          'jumping',\n",
    "          'grazing',\n",
    "          'eating',\n",
    "          'head shake',\n",
    "          'shaking',\n",
    "          'scratch-biting',\n",
    "          'rubbing',\n",
    "          'fighting',\n",
    "          'rolling',\n",
    "          'scared']\n",
    "\n",
    "#Sliding windows\n",
    "TIME_PERIODS = 80\n",
    "STEP_DISTANCE = 40\n",
    "\n",
    "#Datasets\n",
    "FILES = sorted(glob.glob('Data/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-collect",
   "metadata": {},
   "source": [
    "# Set up dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incorporated-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_COLUMNS = ['Mx', 'My', 'Mz','A3D','G3D','M3D'] #Add columns to drop from dataframe\n",
    "\n",
    "def loadDataFrame(files):\n",
    "    \"\"\"\n",
    "    Simple function to set up dataframe and initial clean-up of the data\n",
    "    files: path to files\n",
    "    returns: combined dataframe of all files\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for file in files:\n",
    "        csv = pd.read_csv(file)\n",
    "        csv['filename']=file\n",
    "        df = df.append(csv)\n",
    "        \n",
    "    df.drop(REMOVE_COLUMNS, axis=1, inplace=True)\n",
    "    df['ActivityEncoded'] = le.fit_transform(df['label'].values.ravel())\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_to_float(x):\n",
    "\n",
    "    try:\n",
    "        return np.float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "df = loadDataFrame(FILES)\n",
    "# df.head(5000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-guide",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot data composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moved-layer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# #Training examples per activity type\n",
    "# df['label'].value_counts().plot(kind='bar', title='Training Examples of subject Viva by Activity Type')\n",
    "# plt.show()\n",
    "\n",
    "# SECONDS = 10 #nr of seconds to display accelerometer data\n",
    "# SAMPLING_RATE = 20 #the sampling rate at which data was recorded\n",
    "\n",
    "# def plot_activity(activity, data):\n",
    "\n",
    "#     fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, figsize=(15, 10), sharex=True)\n",
    "#     plot_axis(ax0, data['datetime'], data['Ax'], 'X-Axis')\n",
    "#     plot_axis(ax1, data['datetime'], data['Ay'], 'Y-Axis')\n",
    "#     plot_axis(ax2, data['datetime'], data['Az'], 'Z-Axis')\n",
    "#     plt.subplots_adjust(hspace=0.2)\n",
    "#     fig.suptitle(activity)\n",
    "#     plt.subplots_adjust(top=0.90)\n",
    "#     plt.show()\n",
    "\n",
    "# def plot_axis(ax, x, y, title):\n",
    "\n",
    "#     ax.plot(x, y, 'r')\n",
    "#     ax.set_title(title)\n",
    "#     ax.xaxis.set_visible(False)\n",
    "#     ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\n",
    "#     ax.set_xlim([min(x), max(x)])\n",
    "#     ax.grid(True)\n",
    "\n",
    "# #plot all 3 subplots for each activity\n",
    "# for activity in np.unique(df['label']):\n",
    "#     subset = df[df['label'] == activity][:SECONDS*SAMPLING_RATE] \n",
    "#     plot_activity(activity, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "immune-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column name of the label vector\n",
    "LABEL = 'ActivityEncoded'\n",
    "# Transform the labels from String to Integer via LabelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Add a new column to the existing DataFrame with the encoded values\n",
    "df[LABEL] = le.fit_transform(df['label'].values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-country",
   "metadata": {},
   "source": [
    "# PRE PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-london",
   "metadata": {},
   "source": [
    "- Make all the elements float if they need be\n",
    "- Shuffle data frame\n",
    "- Split to test and train set\n",
    "- Normalize to a range\n",
    "- TODO segment\n",
    "- TODO balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-microphone",
   "metadata": {},
   "source": [
    "# Get only relevant subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hindu-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the indexes of the relevant subjects, see FILES\n",
    "indexes = [0,1,2,7,8,9,13,14,15,16,17]\n",
    "subjects = [FILES[x] for x in indexes]\n",
    "\n",
    "#new dataframe with only the horses in subjects\n",
    "df = df[df['filename'].isin(subjects)]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-victim",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imported-australia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Splitting\n",
    "def splitBySubject(data, name):\n",
    "  '''\n",
    "  Function to split train and test data by subject\n",
    "  data = dataframe\n",
    "  name = subject to put in test subset\n",
    "  '''\n",
    "  test = data[data['filename'].str.contains(name)]\n",
    "  train = data[~data['filename'].str.contains(name)]\n",
    "  return train, test\n",
    "\n",
    "\n",
    "train, test = splitBySubject(df, 'Galoway')\n",
    "\n",
    "print(len(train['filename'].unique()))\n",
    "print(len(test['filename']. unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-olive",
   "metadata": {},
   "source": [
    "# Segmenting 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "local-bracelet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ax</th>\n",
       "      <th>Ay</th>\n",
       "      <th>Az</th>\n",
       "      <th>Gx</th>\n",
       "      <th>Gy</th>\n",
       "      <th>Gz</th>\n",
       "      <th>datetime</th>\n",
       "      <th>label</th>\n",
       "      <th>segment</th>\n",
       "      <th>filename</th>\n",
       "      <th>ActivityEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>54.2</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>2018-06-14 20:06:48.0988</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>58.2</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>2018-06-14 20:06:48.1088</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>26.2</td>\n",
       "      <td>60.6</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>2018-06-14 20:06:48.1188</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>48.7</td>\n",
       "      <td>58.9</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>2018-06-14 20:06:48.1288</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>55.4</td>\n",
       "      <td>-9.1</td>\n",
       "      <td>2018-06-14 20:06:48.1388</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>60.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>2018-06-14 20:06:48.1488</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>50.8</td>\n",
       "      <td>44.5</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>2018-06-14 20:06:48.1588</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>31.4</td>\n",
       "      <td>42.3</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>2018-06-14 20:06:48.1688</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>43.5</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>2018-06-14 20:06:48.1788</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-18.1</td>\n",
       "      <td>48.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2018-06-14 20:06:48.1888</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>52.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018-06-14 20:06:48.1988</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>51.7</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2018-06-14 20:06:48.2088</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>47.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2018-06-14 20:06:48.2188</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2018-06-14 20:06:48.2288</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>41.9</td>\n",
       "      <td>33.4</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2018-06-14 20:06:48.2388</td>\n",
       "      <td>walking-natural</td>\n",
       "      <td>13935</td>\n",
       "      <td>Data/subject_11_Patron_part_1.csv</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ax   Ay  Az    Gx   Gy   Gz                  datetime            label  \\\n",
       "0  6.5 -1.2 3.3 -12.8 54.2 -3.4  2018-06-14 20:06:48.0988  walking-natural   \n",
       "1  6.6 -0.5 3.2   1.7 58.2 -6.8  2018-06-14 20:06:48.1088  walking-natural   \n",
       "2  6.7  0.8 3.5  26.2 60.6 -8.1  2018-06-14 20:06:48.1188  walking-natural   \n",
       "3  6.8  2.1 3.8  48.7 58.9 -8.8  2018-06-14 20:06:48.1288  walking-natural   \n",
       "4  6.8  3.2 4.2  60.0 55.4 -9.1  2018-06-14 20:06:48.1388  walking-natural   \n",
       "5  6.8  3.9 4.7  60.2 50.0 -8.2  2018-06-14 20:06:48.1488  walking-natural   \n",
       "6  6.7  3.5 5.3  50.8 44.5 -6.9  2018-06-14 20:06:48.1588  walking-natural   \n",
       "7  7.2  2.6 5.1  31.4 42.3 -4.8  2018-06-14 20:06:48.1688  walking-natural   \n",
       "8  7.6  1.6 4.3   2.9 43.5 -2.3  2018-06-14 20:06:48.1788  walking-natural   \n",
       "9  7.7  0.8 4.0 -18.1 48.6  1.5  2018-06-14 20:06:48.1888  walking-natural   \n",
       "10 7.7  0.2 3.7 -19.5 52.1  7.0  2018-06-14 20:06:48.1988  walking-natural   \n",
       "11 7.8  0.0 3.3  -9.0 51.7 11.8  2018-06-14 20:06:48.2088  walking-natural   \n",
       "12 8.1  0.3 3.5   6.5 47.7 13.8  2018-06-14 20:06:48.2188  walking-natural   \n",
       "13 8.4  0.7 4.0  25.6 41.0 11.8  2018-06-14 20:06:48.2288  walking-natural   \n",
       "14 9.1  1.3 4.9  41.9 33.4  8.8  2018-06-14 20:06:48.2388  walking-natural   \n",
       "\n",
       "    segment                           filename  ActivityEncoded  \n",
       "0     13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "1     13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "2     13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "3     13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "4     13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "5     13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "6     13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "7     13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "8     13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "9     13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "10    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "11    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "12    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "13    13935  Data/subject_11_Patron_part_1.csv               16  \n",
       "14    13935  Data/subject_11_Patron_part_1.csv               16  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def splitBySegment(data):\n",
    "#     segmented = data[data['segment'].unique()]\n",
    "#     return segmented\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-crowd",
   "metadata": {},
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ordinary-camcorder",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x_max = train['Ax'].max()\n",
    "train_y_max = train['Ay'].max()\n",
    "train_z_max = train['Az'].max()\n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "#divide all 3 axis with the max value in the training set\n",
    "train['Ax'] = train['Ax'] / train_x_max\n",
    "train['Ay'] = train['Ay'] / train_y_max\n",
    "train['Az'] = train['Az'] / train_z_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-mountain",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alternative-huntington",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6033137, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_train = [y for x, y in train.groupby('segment', as_index=False)]\n",
    "seg_test = [y for x, y in test.groupby('segment', as_index=False)]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-cheat",
   "metadata": {},
   "source": [
    "# Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "smart-diesel",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "def createWindows(df, time_steps, step, label_name):\n",
    "    \n",
    "    N_FEATURES = 6\n",
    "    windows = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df)-time_steps, step):\n",
    "        axs = df['Ax'].values[i: i + time_steps]\n",
    "        ays = df['Ay'].values[i: i + time_steps]\n",
    "        azs = df['Az'].values[i: i + time_steps]\n",
    "        \n",
    "        gxs = df['Gx'].values[i: i + time_steps]\n",
    "        gys = df['Gy'].values[i: i + time_steps]\n",
    "        gzs = df['Gz'].values[i: i + time_steps]\n",
    "        # Retrieve the most often used label in this segment\n",
    "        label = stats.mode(df[label_name][i: i + time_steps])[0][0]\n",
    "        windows.append([axs, ays, azs, gxs, gys, gzs])\n",
    "        labels.append(label)\n",
    "\n",
    "    # Bring the segments into a better shape\n",
    "    reshaped_windows = np.asarray(windows, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return reshaped_windows, labels\n",
    "\n",
    "x_trains=[]\n",
    "y_trains=[]\n",
    "for i in seg_train:\n",
    "    x_train, y_train = createWindows(i, 200, 100, LABEL)\n",
    "    x_trains.append(x_train)\n",
    "    y_trains.append(y_train)\n",
    "    \n",
    "\n",
    "#where x_trains[0].shape[0] =! 8 moet eruit\n",
    "one_d_xtrain = []\n",
    "for i in x_trains:\n",
    "    if i.shape[0] == 8:\n",
    "        a = i.astype('float32')\n",
    "        one_d_xtrain.append(a)\n",
    "        \n",
    "one_d_ytrain = []\n",
    "for i in y_trains:\n",
    "    if i.shape[0] == 8:\n",
    "        a = i.astype('float32')\n",
    "        one_d_ytrain.append(a)\n",
    "            \n",
    "print(one_d_xtrain[2].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-avenue",
   "metadata": {},
   "source": [
    "# Suffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "functioning-distance",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_trains[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "thirty-block",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_trains[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "presidential-freeware",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shuffling the whole dataframe\n",
    "# def shuffleData(data_frame):\n",
    "#     '''Function to shuffle dataframe'''\n",
    "#     return data_frame.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# shuf_train = []\n",
    "\n",
    "# for i in seg_train:\n",
    "#     shuf_train.append(shuffleData(i))\n",
    "    \n",
    "    \n",
    "# train = shuf_train\n",
    "# train[0].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-terminology",
   "metadata": {},
   "source": [
    "# Store dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "latter-september",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = 1200\n",
    "x_train_shape = 8\n",
    "num_classes = le.classes_.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dressed-pride",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = (200*6)\n",
    "\n",
    "trainx = []\n",
    "for x in one_d_xtrain:\n",
    "    trainx.append(x.reshape(x.shape[0], input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "linear-letter",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-b6e5b5256c89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mone_d_ytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_d_ytrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'astype'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "decreased-circuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New y_train shape:  (8, 18)\n"
     ]
    }
   ],
   "source": [
    "# Applying one hot coding to y_train\n",
    "y_train_hots = []\n",
    "for i in one_d_ytrain:\n",
    "    y_train_hot = np_utils.to_categorical(i, num_classes)\n",
    "    y_train_hots.append(y_train_hot)\n",
    "print('New y_train shape: ', y_train_hots[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-stanford",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "criminal-employment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 200, 6)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200, 100)          700       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200, 100)          10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200, 100)          10100     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 18)                360018    \n",
      "=================================================================\n",
      "Total params: 380,918\n",
      "Trainable params: 380,918\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_m = Sequential()\n",
    "# Remark: since coreml cannot accept vector shapes of complex shape like\n",
    "# [80,3] this workaround is used in order to reshape the vector internally\n",
    "# prior feeding it into the network\n",
    "model_m.add(Reshape((200, 6), input_shape=(input_shape,)))\n",
    "model_m.add(Dense(100, activation='relu'))\n",
    "model_m.add(Dense(100, activation='relu'))\n",
    "model_m.add(Dense(100, activation='relu'))\n",
    "model_m.add(Flatten())\n",
    "model_m.add(Dense(num_classes, activation='softmax'))\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "hybrid-harrison",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zipped_list = list(zip(trainx, y_train_hots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "informative-summer",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0.], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped_list[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cognitive-velvet",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 1200\n  y sizes: 18\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-9aeafce9075f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         history = model_m.fit(xs,\n\u001b[0m\u001b[1;32m     28\u001b[0m                               \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1527\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[1;32m   1528\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1200\n  y sizes: 18\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='accuracy', patience=1)\n",
    "]\n",
    "\n",
    "model_m.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Hyper-parameters\n",
    "EPOCHS = 2\n",
    "\n",
    "for (x, y) in zipped_list:\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        \n",
    "        xs = np.array(x[i])\n",
    "        ys = np.array(y[i])\n",
    "\n",
    "        history = model_m.fit(xs,\n",
    "                              ys,\n",
    "                              epochs=EPOCHS,\n",
    "                              callbacks=callbacks_list,\n",
    "                              verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hourly-snake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1200) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1200), dtype=tf.float32, name='reshape_1_input'), name='reshape_1_input', description=\"created by layer 'reshape_1_input'\"), but it was called on an input with incompatible shape (None, 200, 6).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 18) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-34c0d6426ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m history = model_m.fit(one_d_xtrain,\n\u001b[0m\u001b[1;32m     21\u001b[0m                       \u001b[0mone_d_ytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /home/rosalie/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 18) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# for loop over segmented data but idk how\n",
    "\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='accuracy', patience=1)\n",
    "]\n",
    "\n",
    "model_m.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Hyper-parameters\n",
    "BATCH_SIZE = 400\n",
    "EPOCHS = 50\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
    "history = model_m.fit(one_d_xtrain,\n",
    "                      one_d_ytrain,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      callbacks=callbacks_list,\n",
    "                      validation_split=0.2,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-matter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
